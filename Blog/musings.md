[Resume](../resume_page.md), [Projects](../projects.md), [Blog](../blog.md)

# Musings
Just a page where I dabble in partially formed thoughts. Getting them onto paper, or rather Web, so that I can more fully form them.

## Websites with Operating Hours
Why a website would have operating hours is more or less beyond me. But I've come across a handful of them. Websites that when access outside of "Normal Business Hours" will display a simple message asking you to come back during specific hours to access the site. I think this sticks in my mind because of how fast web hosting costs can increase. And how much money can be saved by simply cutting down the hours a site is operational during. Of course you always need to have something small running to serve the bare bones come back later message, but that can be handled by an extremely small server, and if you're doing this type of come back later you're likely already getting the vast majority of your traffic at specific times of day. 

I did try for awhile to do something by having a site which was served from a scalable instance that dropped to zero. The issue was that the site typically took far too long to boot up and people grew frustrated with the loading times being drawn out whenever they accessed a site for the first time in awhile. The issue of startup times might be addressed to some extend; however, I have serious doubts it could be gotten down below the 100-200ms that I find online is considered to feel "Instantaneous". Although firecracker vms are supposedly able to start up in under 125ms which is potentially sufficient to acomplish the instantaneous feel that's desired, if with minimal room. One thing I've considered is could a load balancer potentially allow a mix of both operating hours and faster startups. People don't need everything to arrive all at once, they just need it all to be there pretty fast and to start arriving within that timeframe. Potentialy caching the basics of the page and serving those before the actual system has fully started up.

Unfortunately I likely won't get to try out any of these alternate approaches as the system has settled onto a pretty good solution that fits within the needed cost point. The other issues here being that most of the potential methods for getting things setup to handle these ultra fast instant deployments are actually more expensive than simply running traditional virtual machines. 

## The Traveling VM
This is an idea that I've played with when considering the problem of keeping costs low on operating a website which is used throughout the world. If operating hours aren't going to work then the alternative would be to make a single small VM which travels around to be constantly during relative operating hours in the area that its serving. This way if someone is crazy and tries to access the site in the night from their location you can simply make them put up with a larger ping time as they have to access the service from across an ocean or something similar. This isn't actually a terrible idea although it has some downsides that make it not very appealing in a lot of situations.

- You need to have a travel plan for the VM. Say you want to maintain an average ping time of less than 100ms. This is doable; however your VM is going to need to hop from one place to another several times over the day to keep things functional. 
- My guess is that you'd need at least 6 different server locations to make the system function although global ping map data says that you need at least 9 servers to maintain sub 100ms ping times to everywhere on earth. 

![Ping Map - Server Locations](images/PingMap.png)

- You'll notice that this is partially Latitude Dependent as well as Longitude dependent with server locations seperated Vertically as opposed to just Horizontally on the graph. This means that a basic traveling setup wouldn't really be practical. This means that potentially 3 sets of traveling VMs would get you a reasonable ping time during the day. You''ll notice as well that the servers are not properly evenly spaced. This is an unfortunate concequence of where the infrastructure is and how ping time doesn't equate cleanly to physical distance. There would definitely be a secondary problem that these VMs need to cleanly transfer data between one another (User updates when one comes online vs another), this would get expensive. Not just because the data transfer costs between data centers is typically not free, but because it would have a premium transferring in and out of specific cloud providers. 

Honestly based on these things I think the way for this to be handled is with Cloud Functions over entire websites. I once had a spike in cost because my ChatGPT thing was being used by some people in europe while I was deploying to the states. The data transfer costs were while not high, well above the free teir usage that I had expected. Based on this I would say that deploying a cloud function to each of these locations and giving them a small local storage is likely a very valid way to keep costs low. 

## Microcontroller as Everything
One thing that I've noticed as of late is the number of specialized chips that end up being more expensive than simply taking a microcontroller and programming it to fulfill the needed functionality. For instance a design I'm working on currently I need UART to USB conversion; however, instead of placing the UART to USB FTDI chip down and working with that established setup, my current plan is to take an RP2040 chip and use that instead. Essentially allowing me to also gain access to a second UART channel, as well as a plethora of GPIO. In this particular case I'm working with a low powered Microprocessor as well which uses its one USB port for OTG mode, and while it can be configured to overlap the serial port, it's simply convenient to just add a secondary port. Worst case scenario I gain a port whereby I can interact with the RP2040 over the UART and simplify the process of controlling IO.

